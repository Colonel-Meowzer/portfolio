% Created 2020-10-20 Tue 07:50
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{minted}
\author{Dustin Leatherman}
\date{\today}
\title{Quiz 5}
\hypersetup{
 pdfauthor={Dustin Leatherman},
 pdftitle={Quiz 5},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 27.1 (Org mode 9.4)}, 
 pdflang={English}}
\begin{document}

\maketitle

\section{1}
\label{sec:org9c8bf6e}

\begin{quote}
Reggie Jackson hit Y = 10 home runs in N = 27 World Series games. Assume \(Y |
\lambda \sim Poisson(N \lambda)\) where \(\lambda\) is his World Series home run rate.
\end{quote}


\subsection{a}
\label{sec:org3077cb3}

\begin{quote}
The conjugate prior is \(\lambda \sim Gamma(a, b)\). Give the posterior under this prior.
\end{quote}

Posterior of Poisson-Gamma: \(\lambda | Y \sim Gamma(a + Y, b + N)\)

$$
\lambda | Y \sim Gamma(10 + a, 27 + b)
$$

\subsection{b}
\label{sec:orge9d4c29}

\begin{quote}
The Jeffreys prior is \(\pi (\lambda) \propto \lambda^{-1/2}\). Give the posterior
under this prior.
\end{quote}


\begin{equation}
\begin{split}
\lambda | Y \propto & \lambda^Y e^{- \lambda} \cdot \lambda^{-1/2}\\
\propto & \lambda^{Y - 1/2} e^{- \lambda}\\
\propto & \lambda^{(Y + 1/2) - 1} e^{- \lambda}\\
\sim & Gamma(Y + \frac{1}{2}, 1) \sim Gamma(\frac{21}{2}, 1)
\end{split}
\end{equation}

\subsection{c}
\label{sec:org5e34c89}

\begin{quote}
Give one situation where you would use the conjugate prior over the Jeffreys
prior. Defend your answer.
\end{quote}

The conjugate prior would be beneficial over the Jeffreys prior if the
number of home runs over the regular season games were known. The parameters a
and b typically represent the prior number of events and the prior observation
time respectively so the conjugate model is more useful to use if this
information is known.

\subsection{d}
\label{sec:orgf6c9da3}

\begin{quote}
Give one situation where you would use the Jeffreys prior over the conjugate
prior. Defend your answer.
\end{quote}

The only parameter in the Posterior derived from Jeffreys Prior is \(Y\) which is
known in this case. This is useful to use if there is no prior knowledge to
incorporate into the model and the researcher wants to use an objective prior.

\section{2}
\label{sec:orge1fb287}

\begin{quote}
Assume \(Y_1, ..., Y_n\) are independent and \(Y_1, ..., Y_n | \sigma^2 \sim N(0,
\sigma^2)\). The prior is \(\pi (\sigma^2) \propto 1\) for all \(\sigma^2 > 0\).
\end{quote}


\subsection{a}
\label{sec:orge25b47a}

\begin{quote}
Assuming large n, derive the posterior distribution of \(\sigma^2\).
\end{quote}

\begin{equation}
\begin{split}
f(\sigma^2 | Y_1, ..., Y_n) \propto & f(Y_1| \sigma^2) \cdot ... \cdot f(Y_n | \sigma^2) f( \sigma^2)\\
\propto & (\sigma^2)^{- 1/2} e^{- \frac{1}{2 \sigma^2} y_1^2} \cdot ... \cdot  (\sigma^2)^{- 1/2} e^{- \frac{1}{2 \sigma^2} y_n^2} \cdot 1\\
\propto & (\sigma^2)^{-\frac{n}{2}} e^{- \frac{1}{2 \sigma^2} \sum_{i = 1}^{n} y_i^2}\\
\propto & (\sigma^2)^{-(\frac{n}{2} - 1) - 1} e^{- \frac{1}{2 \sigma^2} \sum_{i = 1}^{n} y_i^2}\\
\sim & InvGamma(\frac{n}{2} - 1, \frac{1}{2} \sum_{i = 1}^{n} y_i^2)
\end{split}
\end{equation}

\subsection{b}
\label{sec:orgfb8692b}

\begin{quote}
Give a value of n so that for all n at least as large as this value, the
posterior in (a) is guaranteed to be a proper distribution. Defend your answer.
\end{quote}

To be a proper Gamma and Inverse Gamma distribution, the parameters a and b must
both be positive. Since a is the only parameter using n, it is the only one that
needs to be considered when determining a lower bound for n.


\begin{equation}
\begin{split}
\frac{n}{2} - 1 > & 0\\
\frac{n}{2} > & 1\\
n > & 2
\end{split}
\end{equation}

For all n > 2, the Posterior distribution will be valid.
\end{document}
