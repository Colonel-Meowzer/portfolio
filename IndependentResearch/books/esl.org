#+title:     Elements of Statistical Learning Notes
#+author:    Dustin
#+email:     dustin@dustin-All-Series


This classic text was recommended to me by one of the Lead Data Scientists I used to work with. Here are notes taken upon reading through to gain a deeper understanding of its content.


* Regression with Regularization

** Least Angle Regression (LAR)

p74

An efficient LASSO.

\begin{equation}
\begin{split}
\delta_k  = & \left ( X_{A_k}^T X_{A_k} \right )^{-1} X_{A_k}^T r_k \ \text{Similar to $\hat \beta$}\\
r_k = & y - X_{A_k} \beta_{A_k}\\
\beta_{A_k} (\alpha) = & \beta_{A_k} + \alpha u_k\\
u_k = & X_{A_k} \delta_k \ \text{New Direction}
\end{split}
\end{equation}

Initial $r = y - \bar y$

$u_k$ makes the smallest (and equal) angle with each predictor in $A_k$. Hence, "Least Angle" Regression.

**** Questions
- The equations seem circular?
- What is Arc Length with respect to $L_1$ in LAR/LASSO?

#+begin_quote
Do more research on this. Still don't fully understand it in a way that I can explain it well.
#+end_quote

* Bootstrap Method
Similar to Cross Validation. Creates B datasets from training data by sampling with replacement. Statistics can be calculated from each $B_i$.

For example, $V \left [ S(z) \right ] = \frac{1}{B - 1} \sum_{b = 1}^{B} \left ( S(X^{*b}) - \bar S^{*} \right )^2$ where $S(z)$ is a quantity computed from $B_i$

To prevent overfitting, values present in original training set and a given $B_i$ need to be removed. This is not a problem with Cross Validation since each K is non-overlapping.

*Estimated Error*

\begin{equation}
\begin{split}
\hat {err}^{-1} = \frac{1}{N} \sum_{i = 1}^{N} \frac{1 }{|C^{-i}|} \sum_{}^{b \in C^{-i}} L(y_i, \hat f^{*b} (x_i))
\end{split}
\end{equation}

$C^{-i}$: set of indices of bootstrap samples that do not contain i.

$|C^{-i}|$: number of samples described above.

Subject to training set bias so a 0.632 estimator can be used to alleviate this bias, /which is the average number of distinct observations in each B/.

** 0.632

\begin{equation}
\begin{split}
P(\text{observation} \ i \in \text{Bootstrap Sample} \ b) = & 1 - (1 - \frac{1}{N})^N\\
= & 1 - e^{-1}\\
= & 0.632
\end{split}
\end{equation}

$\hat {err}^{(0.632)} = 0.368 \cdot \bar {err} + 0.632 \cdot \hat {err}^{(1)}$

This works in light fitting situations by can break in overfit ones. However, this can be improved by taking into account he amount of overfitting.


** Relative Overfitting Rate

$\hat R = \frac{\hat {err}^{(1)} - \bar {err}}{\hat \gamma - \bar {err}}$

$\hat R \in (0, 1)$

0: No overfitting
1: if overfitting equals no-info values

$\gamma$: no information error rate. The error rate if inputs and class labels are independent.

$\hat \gamma = \frac{1}{N^2} \sum_{i = 1}^{W} \sum_{i' = 1}^{N} L(y_i, \hat f(x_{i'}))$

* Boosting

Additive Boosting is a technique that weights observations according to how accurate they are. 

$$
G(x) = sign \left ( \sum_{m = 1}^{M} \alpha_m G_m (x) \right )
$$

G: classifier. $G(x) \in \{ -1, 1\}$
x: predictor matrix
M: Iterations of modified datasets
$\alpha_m$: mth weight
$G_m (x)$: mth classifier

Boosting is a way of fitting an additive expansion using a set of elementary /basis/ functions.

*General Form for Basis Function expansion*

$f(x) = \sum_{m = 1}^{M} \beta_m b(x; \gamma_m)$

$\beta_m$: expansion coefficients
x: predictors
$b(x; \gamma_m)$: Simple function taking a matrix X and an m-number of $\gamma$ parameters.

$\gamma_m$ varies by function.

Typical case is to minimize a loss function over training data. Such as squared error or a likelihood-based function.

$$
\underset{\{ \beta_m, \gamma_m\}_1^m}{arg \ min} \sum_{i = 1}^{N} L \left ( y_i, \sum_{m = 1}^{M} \beta_m b(x_i; \gamma_m) \right )
$$

** AdaBoost Algorithm

1. Initialize observation weights $w_i = \frac{1}{N}, \ i = [1, N]$
2. For m = 1 to M:
   a. Fit a classifier $G_m (x)$ to training data using $w_i$
   b. Compute
      $$
      {err}_m = \frac{\sum_{1}^{N} w_i \ I(y_i \neq G_m(x_i))}{\sum_{1}^{N} w_i}
      $$
   c. Compute
      $$
      \alpha_m = log \left ( \frac{1 - {err}_m}{{err}_m} \right )
      $$
   d. Set $w_i$. This increases the relative influence for the next classifier
      $$
      w_i = w_i \cdot exp \left ( \alpha_m \cdot I(y_i \neq G_m(x)) \right ), \ i = [1, N]
      $$
    
3. Output
   $$
   G(x) = sign \left ( \sum_{m = 1}^{M} \alpha_m G_m (x) \right )
   $$
